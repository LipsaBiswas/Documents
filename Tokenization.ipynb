{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMEfCSLR50mCa2sMaC3OKj+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LipsaBiswas/Documents/blob/master/Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaJ_CPSs0aN-"
      },
      "source": [
        "#https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/#:~:text=Tokenization%20is%20a%20common%20task%20in%20Natural%20Language%20Processing%20(NLP).&text=Tokens%20are%20the%20building%20blocks,words%2C%20characters%2C%20or%20subwords.\n",
        "\n",
        "#https://www.machinelearningplus.com/nlp/what-is-tokenization-in-natural-language-processing/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6qfM0b_0ztV"
      },
      "source": [
        "# Tokenization is a pre-processing step in NLP\n",
        "Tokenization is the process of demarcating and possibly classifying sections of a string of input characters  (wikipedia).\n",
        "\n",
        "\n",
        "*   Tokens can be words , characters , sub-words(n-grams).\n",
        "*   Creating vocabulary is the ultimate goal of tokenization.\n",
        "\n",
        "# Word Tokenization\n",
        "\n",
        "\n",
        "\n",
        "*   It is most commonly used\n",
        "*   It splits a piece text into individual words based on some delimiters\n",
        "\n",
        "\n",
        "*   Word2Vec and GloVe used for word tokenization\n",
        "*   Out of vocabulary (OOV) words are drawbacks\n",
        "*   OOVs are mapped with UNK (unknown) tokens\n",
        "*   Subword tokenizers are modern tokenizers\n",
        "*   BPE\n",
        "*   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtsXtEFS6FWz"
      },
      "source": [
        "# Bite Pair Encoding (BPE)  https://leimao.github.io/blog/Byte-Pair-Encoding/\n",
        "* BPE is a algorithm for sub word tokenizatiom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIPuTwlV3-lZ"
      },
      "source": [
        "# word "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZV_DfsM4BQn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d4a124-9d2d-4a1e-d23f-eb96aff07d8b"
      },
      "source": [
        "#Line tokenization\n",
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJq9QBgYK7Ri"
      },
      "source": [
        "sentences = '''\n",
        "The First sentence is about Python. The Second: about Django. You can learn Python,Django and Data Ananlysis here. \n",
        "'''"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRcMNugyLEKr"
      },
      "source": [
        "nltk_tokens = nltk.sent_tokenize(sentences)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCNgF39UTvfL",
        "outputId": "b39fddbf-5247-4b8a-840d-8d2cac8f8b6a"
      },
      "source": [
        "print(nltk_tokens)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\nThe First sentence is about Python.', 'The Second: about Django.', 'You can learn Python,Django and Data Ananlysis here.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_SoHrS1T5an"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK5UJmzXUTa1"
      },
      "source": [
        "# Non-English / Foreign language tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d40XXzEpUYzX",
        "outputId": "1373425f-b6ee-4a1d-990b-d16b1bf0fb98"
      },
      "source": [
        "german_tokenizer = nltk.data.load(\"tokenizers/punkt/german.pickle\")\n",
        "german_sentence_tokens= german_tokenizer.tokenize('Wie geht es dir heute')\n",
        "print(german_sentence_tokens)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Wie geht es dir heute']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovVfTPmgVfrV"
      },
      "source": [
        "# Word tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL4qIlFhViUI"
      },
      "source": [
        "import nltk\n",
        "word_dat ='''\n",
        "it's a beautiful day today , lets go cycling.\n",
        "'''"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq0SjhEnV1qa",
        "outputId": "fec0db4b-d0ee-45a5-9a38-4c066f189662"
      },
      "source": [
        "word_tokens = nltk.word_tokenize(word_dat)\n",
        "print(word_tokens)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['it', \"'s\", 'a', 'beautiful', 'day', 'today', ',', 'lets', 'go', 'cycling', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drFjPMdrWb_l"
      },
      "source": [
        "# Indic Language tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "733h94o4Wvsh",
        "outputId": "e2dd2485-ed85-4a23-a211-841e884d5caa"
      },
      "source": [
        "!pip install -q torch==1.8.1+cpu -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 169.1MB 56kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "547Z2OpYW0rJ",
        "outputId": "cb4bd672-b409-430d-b2d9-dd3a8132fa7e"
      },
      "source": [
        "!pip install -q inltk"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 81kB 2.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 4.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 26.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 41.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 34.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 34.6MB/s \n",
            "\u001b[?25h  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqBRwug4WXBy"
      },
      "source": [
        "# Indic language tokenization\n",
        "import inltk"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBQeHTI3XXXa"
      },
      "source": [
        "odia_sentence ='ଆଜି ତୁମେ କେମିତି ଅଛ? ମୁଁ ତୁମକୁ ଦେଖି ଭଲ ଅନୁଭବ କରୁଛି |'"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJEhHvRaXnTa"
      },
      "source": [
        "from inltk.inltk import tokenize\n",
        " "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "LBbFwcaSX9WC",
        "outputId": "88ba9c08-51dc-4626-da8e-74d3dacf72a4"
      },
      "source": [
        "from inltk.inltk import setup\n",
        "setup('or')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-39512b1c7838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0minltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'or'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/inltk/inltk.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(language_code)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \"\"\"\n\u001b[1;32m    562\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_runnung\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mnew_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfuture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/asyncio/base_events.py\u001b[0m in \u001b[0;36m_check_runnung\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_runnung\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO1wQREEXsoe"
      },
      "source": [
        "odia_tokens = tokenize(odia_sentence , 'or')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpI3Kw50YN4f",
        "outputId": "bc0bc8d0-845a-4b2f-cc4d-6930c18a8d35"
      },
      "source": [
        "print(odia_tokens)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁ଆଜି', '▁ତୁମେ', '▁କେମିତି', '▁ଅ', 'ଛ', '?', '▁ମୁଁ', '▁ତୁମକୁ', '▁ଦେଖି', '▁ଭଲ', '▁ଅନୁଭବ', '▁କରୁଛି', '▁|']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}